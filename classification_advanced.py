import pandas as pd
import torch
from tqdm import tqdm
from transformers import AutoTokenizer, AutoModelForSequenceClassification, ZeroShotClassificationPipeline
from hashlib import md5
import pickle
import json
import argparse
import os
import logging
from typing import Dict, List, Optional
from collections import defaultdict
import logging.handlers
from magic_classifier import (
    tag_csv_with_progress,
    DEFAULT_INPUT_PATH,
    DEFAULT_OUTPUT_PATH,
    DEFAULT_CACHE_PATH,
    DEFAULT_THRESHOLD,
    DEFAULT_TOP_K,
    DEFAULT_BATCH_SIZE,
    DEFAULT_RULES_PRIORITY
)

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('classification.log', encoding='utf-8', mode='w')
    ]
)
logger = logging.getLogger(__name__)

# –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
debug_handler = logging.FileHandler('debug.log', encoding='utf-8', mode='w')
debug_handler.setLevel(logging.DEBUG)
debug_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
debug_handler.setFormatter(debug_formatter)
logger.addHandler(debug_handler)

# –ü–µ—Ä–µ–≤–æ–¥—ã –º–µ—Ç–æ–∫
LABEL_TRANSLATIONS = {
    # –≠—Ñ—Ñ–µ–∫—Ç—ã
    "mentalism": "–º–µ–Ω—Ç–∞–ª–∏–∑–º",
    "prediction": "–ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ",
    "mind reading": "—á—Ç–µ–Ω–∏–µ –º—ã—Å–ª–µ–π",
    "mental revelation": "–º–µ–Ω—Ç–∞–ª—å–Ω–æ–µ –æ—Ç–∫—Ä–æ–≤–µ–Ω–∏–µ",
    "vanish": "–∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ",
    "appearance": "–ø–æ—è–≤–ª–µ–Ω–∏–µ",
    "transformation": "—Ç—Ä–∞–Ω—Å—Ñ–æ—Ä–º–∞—Ü–∏—è",
    "restoration": "–≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ",
    "levitation": "–ª–µ–≤–∏—Ç–∞—Ü–∏—è",
    "penetration": "–ø—Ä–æ–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–µ",
    "transposition": "—Ç—Ä–∞–Ω—Å–ø–æ–∑–∏—Ü–∏—è",
    "teleportation": "—Ç–µ–ª–µ–ø–æ—Ä—Ç–∞—Ü–∏—è",
    "card revelation": "–æ—Ç–∫—Ä–æ–≤–µ–Ω–∏–µ –∫–∞—Ä—Ç—ã",
    "card control": "–∫–æ–Ω—Ç—Ä–æ–ª—å –∫–∞—Ä—Ç—ã",
    "card location": "–ª–æ–∫–∞—Ü–∏—è –∫–∞—Ä—Ç—ã",
    "coin magic": "—Ñ–æ–∫—É—Å—ã —Å –º–æ–Ω–µ—Ç–∞–º–∏",
    "coin vanish": "–∏—Å—á–µ–∑–Ω–æ–≤–µ–Ω–∏–µ –º–æ–Ω–µ—Ç—ã",
    "coin production": "–ø–æ—è–≤–ª–µ–Ω–∏–µ –º–æ–Ω–µ—Ç—ã",
    
    # –†–µ–∫–≤–∏–∑–∏—Ç
    "cards": "–∫–∞—Ä—Ç—ã",
    "coins": "–º–æ–Ω–µ—Ç—ã",
    "phone": "—Ç–µ–ª–µ—Ñ–æ–Ω",
    "paper": "–±—É–º–∞–≥–∞",
    "bills": "–∫—É–ø—é—Ä—ã",
    "magic wand": "–≤–æ–ª—à–µ–±–Ω–∞—è –ø–∞–ª–æ—á–∫–∞",
    "magic box": "–≤–æ–ª—à–µ–±–Ω–∞—è –∫–æ—Ä–æ–±–∫–∞",
    "magic apparatus": "–º–∞–≥–∏—á–µ—Å–∫–∏–π –∞–ø–ø–∞—Ä–∞—Ç",
    "gimmick": "–≥–∏–º–º–∏–∫",
    "prop": "—Ä–µ–∫–≤–∏–∑–∏—Ç",
    "device": "—É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ",
    
    # –ú–∞—Å—à—Ç–∞–± –∏ —Å—Ç–∏–ª—å
    "close-up magic": "–º–∏–∫—Ä–æ–º–∞–≥–∏—è",
    "parlour magic": "—Å–∞–ª–æ–Ω–Ω–∞—è –º–∞–≥–∏—è",
    "stage magic": "—Å—Ü–µ–Ω–∏—á–µ—Å–∫–∞—è –º–∞–≥–∏—è",
    "comedy magic": "–∫–æ–º–µ–¥–∏–π–Ω–∞—è –º–∞–≥–∏—è",
    "serious magic": "—Å–µ—Ä—å—ë–∑–Ω–∞—è –º–∞–≥–∏—è",
    "interactive magic": "–∏–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∞—è –º–∞–≥–∏—è",
    
    # –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    "beginner": "–Ω–∞—á–∏–Ω–∞—é—â–∏–π",
    "intermediate": "—Å—Ä–µ–¥–Ω–∏–π",
    "advanced": "–ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã–π",
    "professional": "–ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π",
    "easy to learn": "–ª–µ–≥–∫–æ —É—á–∏—Ç—Å—è",
    "requires practice": "—Ç—Ä–µ–±—É–µ—Ç –ø—Ä–∞–∫—Ç–∏–∫–∏",
    "requires skill": "—Ç—Ä–µ–±—É–µ—Ç –Ω–∞–≤—ã–∫–∞",
    
    # –¢–∏–ø —Ç–æ–≤–∞—Ä–∞
    "physical product": "—Ñ–∏–∑–∏—á–µ—Å–∫–∏–π —Ç–æ–≤–∞—Ä",
    "digital download": "—Ü–∏—Ñ—Ä–æ–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞",
    "video": "–≤–∏–¥–µ–æ",
    "book": "–∫–Ω–∏–≥–∞",
    "magazine": "–∂—É—Ä–Ω–∞–ª",
    "kit": "–Ω–∞–±–æ—Ä"
}

# 1. –û—Å–Ω–æ–≤–Ω—ã–µ —ç—Ñ—Ñ–µ–∫—Ç—ã
effects_eng = [
    "mentalism", "prediction", "mind reading", "mental revelation",
    "vanish", "appearance", "transformation", "restoration",
    "levitation", "penetration", "transposition", "teleportation",
    "card revelation", "card control", "card location",
    "coin magic", "coin vanish", "coin production"
]

# 2. –†–µ–∫–≤–∏–∑–∏—Ç
props_eng = [
    "cards", "coins", "phone", "paper", "bills",
    "magic wand", "magic box", "magic apparatus",
    "gimmick", "prop", "device"
]

# 3. –ú–∞—Å—à—Ç–∞–± –∏ —Å—Ç–∏–ª—å
scale_eng = [
    "close-up magic", "parlour magic", "stage magic",
    "comedy magic", "serious magic", "interactive magic"
]

# 4. –£—Ä–æ–≤–µ–Ω—å —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
difficulty_eng = [
    "beginner", "intermediate", "advanced", "professional",
    "easy to learn", "requires practice", "requires skill"
]

# 5. –¢–∏–ø —Ç–æ–≤–∞—Ä–∞
product_type_eng = [
    "physical product", "digital download", "video",
    "book", "magazine", "kit"
]

def rule_based_tags(name: str, description: str) -> Dict[str, List[str]]:
    """–ü—Ä–∏–º–µ–Ω—è–µ—Ç –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–≥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∏–º–µ–Ω–∏ –∏ –æ–ø–∏—Å–∞–Ω–∏—è."""
    logger.debug(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª –¥–ª—è: {name}")
    tags = defaultdict(list)
    
    # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ç–∏–ø–∞ —Ç–æ–≤–∞—Ä–∞
    if any(x in name.lower() for x in ["instant download", "digital download", "download"]):
        tags["product_type"].extend(["digital download", "video"])
        logger.debug(f"–ù–∞–π–¥–µ–Ω —Ç–∏–ø —Ç–æ–≤–∞—Ä–∞: digital download, video")
    if any(x in name.lower() for x in ["dvd", "video", "tutorial"]):
        tags["product_type"].append("video")
    if any(x in name.lower() for x in ["book", "manual", "guide"]):
        tags["product_type"].append("book")
    if "magazine" in name.lower():
        tags["product_type"].append("magazine")
    if "kit" in name.lower():
        tags["product_type"].append("kit")
    if not tags["product_type"]:
        tags["product_type"].append("physical product")
    
    # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
    if any(x in name.lower() for x in ["beginner", "easy", "basic"]):
        tags["difficulty"].extend(["beginner", "easy to learn"])
    if "intermediate" in name.lower():
        tags["difficulty"].append("intermediate")
    if any(x in name.lower() for x in ["advanced", "expert"]):
        tags["difficulty"].append("advanced")
    if any(x in name.lower() for x in ["professional", "pro"]):
        tags["difficulty"].append("professional")
    
    # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —Ä–µ–∫–≤–∏–∑–∏—Ç–∞
    if any(x in name.lower() for x in ["card", "deck"]):
        tags["props"].append("cards")
    if any(x in name.lower() for x in ["coin", "coins"]):
        tags["props"].append("coins")
    if any(x in name.lower() for x in ["phone", "smartphone"]):
        tags["props"].append("phone")
    if any(x in name.lower() for x in ["wand", "stick"]):
        tags["props"].append("magic wand")
    if any(x in name.lower() for x in ["box", "case"]):
        tags["props"].append("magic box")
    if any(x in name.lower() for x in ["gimmick", "gimmicked"]):
        tags["props"].append("gimmick")
    if any(x in name.lower() for x in ["apparatus", "device"]):
        tags["props"].append("magic apparatus")
    
    # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∞
    if any(x in name.lower() for x in ["close-up", "closeup", "table"]):
        tags["scale"].append("close-up magic")
    if any(x in name.lower() for x in ["parlour", "parlor", "parlour"]):
        tags["scale"].append("parlour magic")
    if any(x in name.lower() for x in ["stage", "show"]):
        tags["scale"].append("stage magic")
    if any(x in name.lower() for x in ["comedy", "funny"]):
        tags["scale"].append("comedy magic")
    if any(x in name.lower() for x in ["serious", "professional"]):
        tags["scale"].append("serious magic")
    if any(x in name.lower() for x in ["interactive", "audience"]):
        tags["scale"].append("interactive magic")
    
    # –ü—Ä–∞–≤–∏–ª–∞ –¥–ª—è —ç—Ñ—Ñ–µ–∫—Ç–æ–≤
    if any(x in name.lower() for x in ["mental", "mind", "psychic"]):
        tags["effect"].append("mentalism")
    if any(x in name.lower() for x in ["predict", "prediction"]):
        tags["effect"].append("prediction")
    if any(x in name.lower() for x in ["vanish", "disappear"]):
        tags["effect"].append("vanish")
    if any(x in name.lower() for x in ["appear", "production"]):
        tags["effect"].append("appearance")
    if any(x in name.lower() for x in ["transform", "change"]):
        tags["effect"].append("transformation")
    if any(x in name.lower() for x in ["restore", "restoration"]):
        tags["effect"].append("restoration")
    if "levitation" in name.lower():
        tags["effect"].append("levitation")
    
    return dict(tags)

def get_args():
    parser = argparse.ArgumentParser(description='–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è CSV —Ñ–∞–π–ª–∞ —Å —Ç–µ–≥–∞–º–∏')
    parser.add_argument('--input', type=str, default=DEFAULT_INPUT_PATH, help='–ü—É—Ç—å –∫ –≤—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É')
    parser.add_argument('--output', type=str, default=DEFAULT_OUTPUT_PATH, help='–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV —Ñ–∞–π–ª—É')
    parser.add_argument('--limit', type=int, default=30, help='–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–∞ —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--threshold', type=float, default=DEFAULT_THRESHOLD, help='–ü–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏ –¥–ª—è —Ç–µ–≥–æ–≤')
    parser.add_argument('--top_k', type=int, default=DEFAULT_TOP_K, help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–π –∫–∞—Ç–µ–≥–æ—Ä–∏–∏')
    parser.add_argument('--batch_size', type=int, default=DEFAULT_BATCH_SIZE, help='–†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏')
    parser.add_argument('--cache', type=str, default=DEFAULT_CACHE_PATH, help='–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É –∫—ç—à–∞')
    parser.add_argument('--force', action='store_true', help='–ò–≥–Ω–æ—Ä–∏—Ä–æ–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–π –∫—ç—à')
    parser.add_argument('--rules_priority', type=str, default=DEFAULT_RULES_PRIORITY, 
                      choices=['append', 'prefer_rules', 'prefer_model'],
                      help='–ö–∞–∫ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å rule-based —Ç–µ–≥–∏ vs –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–æ–¥–µ–ª–∏')
    return parser.parse_args()

def limit_tags_json(tag_scores: dict, max_tags: int = 10) -> dict:
    """–û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ–≥–æ–≤ –≤ tags_json."""
    all_scores = []
    for cat_scores in tag_scores.values():
        all_scores.extend(cat_scores.items())
    
    return dict(sorted(all_scores, key=lambda x: -x[1])[:max_tags])

def translate_tags(tags: List[str]) -> List[str]:
    """–ü–µ—Ä–µ–≤–æ–¥–∏—Ç —Ç–µ–≥–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫."""
    return [LABEL_TRANSLATIONS.get(tag, tag) for tag in tags]

def save_partial_results(df: pd.DataFrame, output_path: str, row_count: int):
    """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
    base, ext = os.path.splitext(output_path)
    partial_path = f"{base}.autosave_{row_count}{ext}"
    df.to_csv(partial_path, index=False)
    logging.info(f"–°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã: {partial_path}")

def generate_report(stats: dict) -> str:
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –æ—Ç—á—ë—Ç –æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞—Ö –æ–±—Ä–∞–±–æ—Ç–∫–∏."""
    report = ["üìä –û—Ç—á—ë—Ç:"]
    report.append(f"‚úî –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {stats['total_rows']} —Å—Ç—Ä–æ–∫")
    
    for cat in ['effect', 'props', 'scale', 'difficulty', 'product_type']:
        avg_tags = stats['tags_per_category'][cat] / stats['total_rows']
        report.append(f"   {cat:<12} ‚Äî –≤ —Å—Ä–µ–¥–Ω–µ–º {avg_tags:.1f} —Ç–µ–≥–∞(–æ–≤)/—Å—Ç—Ä–æ–∫—É")
    
    return "\n".join(report)

def load_cache(cache_path):
    if os.path.exists(cache_path):
        with open(cache_path, 'rb') as f:
            return pickle.load(f)
    return {}

def save_cache(cache, cache_path):
    with open(cache_path, 'wb') as f:
        pickle.dump(cache, f)

def batch_infer(classifier, descs, labels):
    # descs: —Å–ø–∏—Å–æ–∫ –æ–ø–∏—Å–∞–Ω–∏–π, labels: —Å–ø–∏—Å–æ–∫ –º–µ—Ç–æ–∫
    results = classifier(descs, labels, multi_label=True)
    # results ‚Äî —Å–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π (–∏–ª–∏ –æ–¥–∏–Ω —Å–ª–æ–≤–∞—Ä—å, –µ—Å–ª–∏ 1 –æ–ø–∏—Å–∞–Ω–∏–µ)
    if isinstance(results, dict):
        results = [results]
    return results

def tag_csv_with_progress(input_file, output_file, limit=None, threshold=0.3, top_k=3, batch_size=8, cache_file='cache.pkl', force=False, rules_priority='append'):
    try:
        logger.info(f"–ü–∞—Ä–∞–º–µ—Ç—Ä limit: {limit}")
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫—ç—à, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –∏ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —Ñ–ª–∞–≥ force
        cache = {}
        if os.path.exists(cache_file) and not force:
            try:
                with open(cache_file, 'rb') as f:
                    cache = pickle.load(f)
                logging.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω –∫–µ—à –∏–∑ {cache_file}, –∑–∞–ø–∏—Å–µ–π: {len(cache)}")
            except Exception as e:
                logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ –∫–µ—à–∞: {str(e)}")
                cache = {}

        logger.info("–ù–∞—á–∏–Ω–∞–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É —Ñ–∞–π–ª–∞...")
        df = pd.read_csv(input_file)
        logger.info(f"–ó–∞–≥—Ä—É–∂–µ–Ω —Ñ–∞–π–ª {input_file}, —Å—Ç—Ä–æ–∫: {len(df)}")
        
        if limit:
            df = df.head(limit)
            logger.info(f"–ü—Ä–∏–º–µ–Ω–µ–Ω–æ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ: {limit} —Å—Ç—Ä–æ–∫")

        device = 0 if torch.cuda.is_available() else -1
        logger.info(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {'CUDA' if device == 0 else 'CPU'}")
        
        logger.info("–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä–∞...")
        tokenizer = AutoTokenizer.from_pretrained("facebook/bart-large-mnli")
        model = AutoModelForSequenceClassification.from_pretrained("facebook/bart-large-mnli")
        classifier = ZeroShotClassificationPipeline(model=model, tokenizer=tokenizer, device=device, batch_size=batch_size)
        logger.info("–ú–æ–¥–µ–ª—å –∏ —Ç–æ–∫–µ–Ω–∏–∑–∞—Ç–æ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã")

        categories = [
            ("effect", effects_eng),
            ("props", props_eng),
            ("scale", scale_eng),
            ("difficulty", difficulty_eng),
            ("product_type", product_type_eng)
        ]

        results = []
        all_json = []
        progress = tqdm(total=len(df), desc="Classifying", dynamic_ncols=True)

        # –°–ø–∏—Å–æ–∫ –∏–Ω–¥–µ–∫—Å–æ–≤, –∫–æ—Ç–æ—Ä—ã–µ –Ω—É–∂–Ω–æ –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å (–Ω–µ—Ç –≤ –∫–µ—à–µ)
        to_process = []
        for i, row in df.iterrows():
            if limit and i >= limit:
                break
            desc = str(row.get("description", "")).strip()
            name = str(row.get("name", "")).strip()
            if not desc or desc.lower() == 'nan':
                logger.debug(f"–ü—Ä–æ–ø—É—â–µ–Ω–∞ —Å—Ç—Ä–æ–∫–∞ {i}: –ø—É—Å—Ç–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ")
                continue
            h = md5(desc.encode()).hexdigest()
            if h not in cache:
                to_process.append((i, desc, name))
        
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {len(to_process)} —Å—Ç—Ä–æ–∫ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–Ω–µ –≤ –∫–µ—à–µ)")

        # –ë–∞—Ç—á–∏–Ω–≥ –æ–ø–∏—Å–∞–Ω–∏–π
        for start in range(0, len(to_process), batch_size):
            batch = to_process[start:start+batch_size]
            logger.debug(f"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {start//batch_size + 1}, —Ä–∞–∑–º–µ—Ä: {len(batch)}")
            
            batch_indices = [i for i, _, _ in batch]
            batch_descs = [desc for _, desc, _ in batch]
            batch_names = [name for _, _, name in batch]
            batch_results = {}
            
            # –ü–æ–ª—É—á–∞–µ–º rule-based —Ç–µ–≥–∏
            rule_tags = [rule_based_tags(name, desc) for name, desc in zip(batch_names, batch_descs)]
            logger.debug(f"–ü–æ–ª—É—á–µ–Ω—ã rule-based —Ç–µ–≥–∏ –¥–ª—è –±–∞—Ç—á–∞: {rule_tags}")
            
            for cat, labels in categories:
                cat_results = batch_infer(classifier, batch_descs, labels)
                for idx, res, rule_tag in zip(batch_indices, cat_results, rule_tags):
                    desc_val = str(df.loc[idx, "description"]).strip()
                    if not desc_val or desc_val.lower() == 'nan':
                        continue
                    h = md5(desc_val.encode()).hexdigest()
                    if h not in cache:
                        cache[h] = {}
                    
                    # –ü—Ä–∏–º–µ–Ω—è–µ–º –ø—Ä–∞–≤–∏–ª–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
                    if rules_priority == 'prefer_rules' and rule_tag.get(cat):
                        cache[h][cat] = {tag: 1.0 for tag in rule_tag[cat]}
                    elif rules_priority == 'prefer_model':
                        cache[h][cat] = dict(zip(res["labels"], res["scores"]))
                    else:  # append
                        model_scores = dict(zip(res["labels"], res["scores"]))
                        rule_scores = {tag: 1.0 for tag in rule_tag.get(cat, [])}
                        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ç–µ–≥–∏, –æ—Ç–¥–∞–≤–∞—è –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–µ –ø—Ä–∞–≤–∏–ª–∞–º
                        combined = {**model_scores, **rule_scores}
                        cache[h][cat] = combined
                        
            progress.update(len(batch))

        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π —Å—Ç—Ä–æ–∫–∏
        tags_per_category = {cat: 0 for cat, _ in categories}
        cache_hits = 0
        for i, row in df.iterrows():
            desc = str(row.get("description", "")).strip()
            name = str(row.get("name", "")).strip()
            if not desc or desc.lower() == 'nan':
                tag_json = {}
                all_json.append(json.dumps(tag_json, ensure_ascii=False))
                tags = {cat: [] for cat, _ in categories}
                tags_ru = {cat: [] for cat, _ in categories}
                results.append({**tags, **{cat+"_ru": tags_ru[cat] for cat in tags_ru}})
                continue
            h = md5(desc.encode()).hexdigest()
            tag_json = cache.get(h, {})
            if h in cache:
                cache_hits += 1
            all_json.append(json.dumps(tag_json, ensure_ascii=False))
            tags = {cat: [] for cat, _ in categories}  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            tags_ru = {cat: [] for cat, _ in categories}  # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—É—Å—Ç—ã–µ —Å–ø–∏—Å–∫–∏ –¥–ª—è –≤—Å–µ—Ö –∫–∞—Ç–µ–≥–æ—Ä–∏–π
            for cat, labels in categories:
                tag_scores = tag_json.get(cat, {})
                filtered = [label for label, score in sorted(tag_scores.items(), key=lambda x: -x[1]) if score >= threshold]
                if top_k:
                    filtered = filtered[:top_k]
                tags[cat] = filtered
                tags_ru[cat] = [LABEL_TRANSLATIONS.get(label, label) for label in filtered]
                tags_per_category[cat] += len(filtered)
            results.append({**tags, **{cat+"_ru": tags_ru[cat] for cat in tags_ru}})
        progress.close()
        # –î–æ–±–∞–≤–ª—è–µ–º –∫–æ–ª–æ–Ω–∫–∏
        for cat, _ in categories:
            df[cat] = [r[cat] for r in results]
            df[cat+"_ru"] = [r[cat+"_ru"] for r in results]
        df["tags_json"] = all_json
        df.to_csv(output_file, index=False)
        print(f"‚úî Done! Saved to: {output_file}")
        save_cache(cache, cache_file)
        print(f"–ö–µ—à —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {cache_file}")
        # –§–∏–Ω–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç
        total_rows = len(df)
        print("\nüìä –û—Ç—á—ë—Ç:")
        print(f"‚úî –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_rows} —Å—Ç—Ä–æ–∫")
        for cat in tags_per_category:
            avg = tags_per_category[cat] / total_rows if total_rows else 0
            print(f"   {cat:<12} ‚Äî –≤ —Å—Ä–µ–¥–Ω–µ–º {avg:.1f} —Ç–µ–≥–∞(–æ–≤)/—Å—Ç—Ä–æ–∫—É")
        print(f"‚úî –ö–µ—à-—Ö–∏—Ç–æ–≤: {cache_hits} –∏–∑ {total_rows}")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞: {str(e)}")

if __name__ == "__main__":
    args = get_args()
    tag_csv_with_progress(args.input, args.output, args.limit, args.threshold, args.top_k, args.batch_size, args.cache, args.force, args.rules_priority) 